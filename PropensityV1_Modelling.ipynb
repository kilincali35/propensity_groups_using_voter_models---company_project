{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CM_tumTkDySv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd ~/Ali/FBB/Propensity"
      ],
      "metadata": {
        "id": "p55L-PlWD1UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "n_cpu= os.cpu_count() print(n_cpu)"
      ],
      "metadata": {
        "id": "cDS9Pc2ND1fC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pymysql \n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import seaborn as sns \n",
        "import feature_engine \n",
        "import warnings\n",
        "import mysql.connector\n",
        "import inspect\n",
        "import matplotlib.pyplot as plt warnings.filterwarnings ('ignore')\n",
        "pd.set_option('display.max_columns', 40) \n",
        "pd.set_option('display.width', 120) \n",
        "from sqlalchemy import create engine \n",
        "from datetime import datetime \n",
        "import timeit\n",
        "start_time = timeit.default_timer()"
      ],
      "metadata": {
        "id": "NuUIPi3mD1iu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ai = {}\n",
        "ai['user'] = 'user'\n",
        "ai['password'] = 'pwd'\n",
        "ai['name'] = 'AI'\n",
        "ai['host'] = '10.10.10.10'\n",
        "ai['port'] = 3333\n",
        "\n",
        "prod = {}\n",
        "prod['user'] = 'user'\n",
        "prod['password'] = 'pwd'\n",
        "prod['name'] = 'AI'\n",
        "prod['host'] = '10.10.10.10'\n",
        "prod['port'] = 3333"
      ],
      "metadata": {
        "id": "B3ZiwIjCD1l6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_query(cred, db,query):\n",
        "  try:\n",
        "    mydb = mysql.connector.connect(\n",
        "          host=cred['host'],\n",
        "          port=cred['port'],\n",
        "          user=cred['user'],\n",
        "          password=cred['password'],\n",
        "          database=db\n",
        "    )\n",
        "    df = pd.read_sql(query,mydb) \n",
        "    mydb.close()\n",
        "    return df#close the connection \n",
        "  except Exception as e:\n",
        "    print(str(e))\n",
        "\n",
        "def update_query(cred, db,query):\n",
        "  try:\n",
        "    mydb = mysql.connector.connect(\n",
        "          host=cred['host'],\n",
        "          port=cred['port'],\n",
        "          user=cred['user'],\n",
        "          password=cred['password'],\n",
        "          database=db\n",
        "    )\n",
        "    mycursor mydb.cursor()\n",
        "    mycursor.execute(query)\n",
        "    mydb.commit()\n",
        "    mydb.close()\n",
        "    return print(mycursor.rowcount, \"record(s) affected\") \n",
        "  except Exception as e:\n",
        "    print(str(e))"
      ],
      "metadata": {
        "id": "VMfwq509D1pT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "script_pars ={\n",
        "      'explanation': 'Model seems fine on production, on lookup prediction there are some flaws, eliminated all pivot and btn variables. Seems like NA pivots also effect', \n",
        "      'discard_btnh': 1,\n",
        "      'target': 'is_sale',\n",
        "      'discard_pivot': 1,\n",
        "      'sme_limit':' limit 10000000', #Use it if you want to limit nrows for sme query. Otherwise just ''\n",
        "      'database': 'smexplorerdata_fbb', #sme database\n",
        "      'table_to_use': 'smexplorerdata_fbb.fbb_ob_sme_view', #name of the sme\n",
        "      'neg_pos_ratio': 2, #This is for balancing the dataset. 2 means proportion of target to 1 will be 2:1, and 1 ratio will be 33% \n",
        "      'val_split': 'lastN', #Determines the type of validation data split. Shuffle will use a stratified train_test_split\n",
        "                            # 2nd option is 'lastN'. It will spare the last N days as validation data\n",
        "      'shuffle_test_size': 0.1, #If you are using shuffle, determine the validation data share. Use to skip it and use all data\n",
        "      'lastn_days': 20, #Last N days parameter for split option lastN\n",
        "      'min_day_pct': 0.7, #When you are using last days, you can set a parameter that accidentally sets a large portion of data as validation data\n",
        "                          #In order to prevent that, you can set this parameter, it looks at distinct days in data, and sets a minimum day limit for validation data beginning \n",
        "      'dropna_thresh': 0.5, #Set a threshold for dropping columns having greater null percentage than that value\n",
        "      'dropcor_thresh': 0.7, #Set a threshold to drop correlated numerical features having correlation coefficient larger than that\n",
        "      'feature_selection': 1, #If you want to apply a RFECV feature selection step to shrink column size before modeling\n",
        "      #'rfecv_est': dt, # Which estimator do you want to use for RFECV. dt for decision tree, lgb for lightgbm, pi is inactive due to library issues now but permutation imp \n",
        "      'rfecv_min_feat': 50, #How many features will remain in dataset afterwards as a minimum\n",
        "      'run_type': 'prod', #adds a suffix to models folder, you can use 'prod' or 'test'\n",
        "      'preferred_folder_name': '', #If you have a folder name containing pickle files you want to make predictions write it.'' is suggested, to get latest created one on run type \n",
        "      'top_n_models': 3 #Among all voter models, it chooses top_n models to get average probability\n",
        "}"
      ],
      "metadata": {
        "id": "W887NNryFhgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we have a large amount of variables, so we need to handle them manually in preprocessing.\n",
        "#this csv file keeps variable names, their real dtypes and decide whether they should be discarded or not \n",
        "var_df = pd.read_csv('varlist_fbb_new.csv', na_values = '', delimiter = ', ')\n",
        "var_df['name'] = var_df['name'].str.lower()\n",
        "var_df.loc[var_df ['name'].isin(['calldate', 'conn_id']), 'discard'] = 0\n",
        "\n",
        "if script_pars['discard_btnh'] == 1:\n",
        "  var_df.loc[var_df['name'].isin([col for col in var_df['name'].unique() if col.startswith('btnh_')]), 'discard'] = 1\n",
        "if script_pars['discard_pivot'] == 1:\n",
        "  var_df.loc[var_df['name'].isin([col for col in var_df['name'].unique() if col.startswith('pivot_')]), 'discard'] = 1\n",
        "\n",
        "var_df.loc[var_df['name'].isin(['feata', 'featb', 'featc', 'featd', 'feate']), 'discard'] = 1\n",
        "\n",
        "var_drop = list(var_df ['name'][var_df['discard'] ==1])\n",
        "\n",
        "var_df.drop(var_df.loc[var_df['name'].isin(var_drop) ==True].index, inplace = True)\n",
        "var_df.reset_index(drop=True, inplace=True)\n",
        "print(var_df.head())\n",
        "\n",
        "str_vars=\", \".join(var_df['name']) \n",
        "print(str_vars)"
      ],
      "metadata": {
        "id": "ozpk8j7QFhme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#your query\n",
        "query = \"\"\"select \"\"\" + str_vars + \"\"\" from \"\"\" + script_pars['table_to_use'] + \"\"\" where calltime >= '2022-12-01' and is_sale is not null and (calltime not between '2023-02-05' and '2023-02-20)\n",
        "and !isnull(agent_id) and agent_id <>'' and agent_id <> ' ' and isrelevant = 1 and proje_tipi in ('Retention', 'Retention_\") \"\"\" +script_pars['sme_limit']+\"\"\" ;\"\"\" \n",
        "\n",
        "pre_df = run_query(ai, script_pars['database'], query)\n",
        "print(pre_df.head (5))"
      ],
      "metadata": {
        "id": "E9tnp5c8FhqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df = pre_df.replace('NA', np.nan)\n",
        "pre_df = pre_df.replace(\"NULL\", np.nan) \n",
        "pre_df.columns= pre_df.columns.str.lower()\n",
        "var_drop = [col.lower() for col in var_drop]\n",
        "\n",
        "pre_df.drop(columns = [col for col in var_drop if col in pre_df.columns], axis=1, inplace=True)\n",
        "#var_df['type'] = np.where(war_df['name'].isin([xxxx]), 'category', var_df['type'])\n",
        "var_df['type'] = np.where(var_df ['type'].isin(['int']), 'Int64', var_df['type'])\n",
        "print(pre_df.isna().sum())\n",
        "print(pre_df.head())"
      ],
      "metadata": {
        "id": "DATK2Tf7FhtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cardinality check, it can also be automated\n",
        "print(pre_df.nunique().sort_values (ascending=False).head (40))\n",
        "print(len(pre_df))\n",
        "#print(variable5.value_counts().sort_values (ascendint=False))"
      ],
      "metadata": {
        "id": "1Vm_mVHDFhwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df_cols = pre_df.columns\n",
        "varlist = list(var_df['name'].str.lower())\n",
        "print(len(pre_df_cols))\n",
        "\n",
        "var_df.loc[var_df['name'].isin(['cmpg_acik_sikayet_kaydi', 'cmpg_risk_skoru']), 'type'] = 'category'\n",
        "\n",
        "#changing python dtypes and if they are different than our list, change dtype. Float thing was not necessary, but after so many errors inside pipe, i needed to do it \n",
        "for i in range(len(pre_df_cols)):\n",
        "  print(i)\n",
        "  if var_df.loc[i, 'type'] == 'datetime64\":\n",
        "    #main_df[main_df_cols[i]] = pd.to_datetime (main_df[main_df_cols[i]], format = var_df.loc[i, 'timetype'], errors = 'coerce')\n",
        "    pass\n",
        "  if var_df.loc[i, 'type'] == 'Int64\":\n",
        "    print (pre_df_cols[i])\n",
        "    print(var_df.loc[i, 'type'])\n",
        "    pre_df [pre_df_cols[i]] = pre_df[pre_df_cols[i]].astype('float')\n",
        "    pre_df[pre_df_cols[i]] = pre_df[pre_df_cols[i]].astype(var_df.loc[i, 'type'])\n",
        "  else:\n",
        "    print (pre_df_cols[i])\n",
        "    print(var_df.loc[i, 'type'])\n",
        "    pre_df [pre_df_cols[i]] = pre_df[pre_df_cols[i]].astype (var_df.loc[i, 'type'])"
      ],
      "metadata": {
        "id": "YMlRnI8pFhzW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(pre_df.isnull(). mean()*100,2).sort_values (ascending = False))"
      ],
      "metadata": {
        "id": "1UVgE8AJD1x4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if [i for i in ['feata', 'featb'] if i in pre_df.columns]:\n",
        "  print(\"It is in columns\")\n",
        "  \n",
        "  ### !!!!!!! This is an important concept with 2 outcomes to be used in future. This cell is only for test purpose. \n",
        "  ### Replace is not workint with INPLACE parameter anymore, you need to specify it explicitly\n",
        "  ### And if the DTYPE is not OBJECT, replacing NP.NAN value with a fixed string value is not working. You need to change DTYPE \n",
        "  pre_df_test = pre_df.copy()\n",
        "  pre_df_test[['feata', 'featb']] = pre_df_test[['feata', 'featb']].replace(np.nan, 'NA')\n",
        "  print (pre_df_test[['feata', 'featb']].head(10))\n",
        "\n",
        "  pre_df_test[['feata', 'featb']] = pre_df_test[['feata', 'featb']].astype('object') \n",
        "  pre_df_test[['feata','featb']] = pre_df_test[['feata', 'featb']].replace(np.nan, 'NA')\n",
        "  print(pre_df_test[['feata', 'featb']].head(10))\n",
        "\n",
        "  ### Here is the 2nd variatoin, using fillna. But it needs to see it as a new category\n",
        "  ### And also add_category is only using series, one column each time. So, i used a lambda funtion to apply it properly\n",
        "  #These features are filled with NA because features are populated only if there is a cancellation application. So, missing values have meaning here\n",
        "  pre_df[['feata', 'featb']] = pre_df[['feata','featb']].apply(lambda x: x.cat.add_categories('NA').fillna('NA')) \n",
        "  print(pre_df[['feata', 'featb']].head())"
      ],
      "metadata": {
        "id": "_SkSR1wpIl3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(round(pre_df.isnull().mean()*100,2).sort_values(ascending = False))"
      ],
      "metadata": {
        "id": "ntOcxxOMIl6y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### NA value filling is a complicated issue. So far i have only filled the columns which NaN values have meaning, and not missing information.\n",
        "### For other ones, according to the requirements of algorithms, i will fill them with median or most frequent values inside trainin pipelines (Leakage issues) \n",
        "### And as a first step, during analysis of data, such columns should be determined, the ones that NaN values has a meaning, can be replaced as a category."
      ],
      "metadata": {
        "id": "pHZGpM2IIl-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Since it is random over/under sampling, it is not deeply connected to preprocessing steps we will apply. It can be before or after preprocessing.\n",
        "### I was just thinking to calculate null value percentages etc with full population, but it may be better to solve imbalance first.\n",
        "### Because we are deailing with null values etc to make model better. But, when we do them first, then solve imbalance. randomly, we may come across with new Na issue etc. \n",
        "import math\n",
        "\n",
        "#imbalance check\n",
        "pre_df_copy = pre_df.copy()\n",
        "pos_pre_df = pre_df [pre_df['is_sale']==1].reset_index(drop=True)\n",
        "neg_pre_df = pre_df[pre_df['is_sale']==0].reset_index(drop=True) \n",
        "num_positive = pos_pre_df.shape[0]\n",
        "num_negative neg_pre_df.shape[0]\n",
        "neg_pos_ratio= script_pars['neg_pos_ratio']\n",
        "print(len(pos_pre_df))\n",
        "print(len(neg_pre_df))\n",
        "main_df = pre_df.copy()\n",
        "\n",
        "np.random.seed(35) #1000 first\n",
        "#sampling_idx = np.random.randint(0, neg_pre_df.shape[0], math.floor(num_positive*neg_pos_ratio)).tolist()\n",
        "sampling_idx= np.random.choice(range(neg_pre_df.shape[0]), math.floor(num_positive*neg_pos_ratio), replace = False).tolist()\n",
        "\n",
        "sampling_idx.sort()\n",
        "sub_neg_df = neg_pre_df.iloc[sampling_idx, :]\n",
        "\n",
        "outsamp_neg_df = neg_pre_df.iloc[~neg_pre_df.index.isin(sampling_idx), :] \n",
        "#outsamp_neg_df = neg_pre_df.iloc[outsamp_ind, :]\n",
        "\n",
        "print(len(sub_neg_df))\n",
        "#outsamp_neg_df = neg_pre_df[~neg_pre_df.index.isin(sampling_idx)] \n",
        "print(len(outsamp_neg_df))\n",
        "\n",
        "main_df = pos_pre_df.append(sub_neg_df).reset_index(drop=True)\n",
        "\n",
        "#shuffling dataset 5 times to randomise output var again\n",
        "for i in range(5):\n",
        "  idx = np.random.permutation(main_df.index)\n",
        "  main_df = main_df.reindex(idx)\n",
        "\n",
        "main_df = main_df.reset_index(drop=True)\n",
        "outsamp_neg_df = outsamp_neg_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "4HShBcduImCJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "if (script_pars['val_split'] == 'shuffle') and (script_pars['shuffle_test_size'] > 0):\n",
        "  \n",
        "  main_df, val_df = train_test_split(main_df, test_size = script_pars['shuffle_test_size'], stratify = main_df['is_sale'], random_state = 35) \n",
        "  main_df['is_val'] = 0\n",
        "  val_df['is_val'] = 1\n",
        "  outsamp_neg_df ['is_val'] = 2\n",
        "  main_df = main_df.append(val_df, ignore_index = True)\n",
        "  main_df = main_df.append(outsamp_neg_df, ignore_index = True)\n",
        "\n",
        "elif script_pars['val_split'] == 'lastN':\n",
        "  max_dt = max(main_df['calldate'])\n",
        "  min_dt = min(main_df['calldate'])\n",
        "  thr_day = max_dt - timedelta(days = script_pars['lastn_days'])\n",
        "\n",
        "  #Active days list\n",
        "  window_days = main_df['calldate'].nunique()\n",
        "  \n",
        "  # Thr_day looks at only active call_dates, and sets a minimum threshold to them according to x% of the active days. \n",
        "  thr_day_limit = sorted(main_df['calldate'].unique())[math.ceil (window_days*script_pars['min_day_pct'])+1] \n",
        "  print(thr_day)\n",
        "  print(thr_day_limit)\n",
        "  print(max(thr_day, thr_day_limit))\n",
        "  main_df['is_val'] = 0\n",
        "  main_df['is_val'][main_df['calldate']>=max(thr_day, thr_day_limit)] = 1\n",
        "\n",
        "  outsamp_neg_df['is_val'] = 2\n",
        "  main_df = main_df.append(outsamp_neg_df, ignore_index = True)\n",
        "\n",
        "else:\n",
        "\n",
        "  main_df['is_val'] = 0\n",
        "  outsamp_neg_df['is_val'] = 2\n",
        "  main_df = main_df.append(outsamp_neg_df, ignore_index = True)\n",
        "\n",
        "print(main_df['is_val'].value_counts()) "
      ],
      "metadata": {
        "id": "mouAq8WKKfLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#setting a NA threshold and dropping vars according to that. Also fix, empty and duplicate columns are deleted. \n",
        "main_df.dropna(axis=1, thresh = int(script_pars['dropna_thresh']*(main_df.shape[0])), inplace=True)\n",
        "\n",
        "df_y=main_df[['is_sale', 'is_val']]\n",
        "print(df_y['is_val'].value_counts())\n",
        "main_df.drop(columns = ['is_sale'], axis= 1, inplace=True)\n",
        "\n",
        "fix_cols = []\n",
        "for col in [col for col in main_df.columns if col not in ['is_val']]:\n",
        "  if main_df[col].nunique() == 1:\n",
        "    fix_cols.append(col)\n",
        "  else:\n",
        "    pass\n",
        "\n",
        "emp_cols = []\n",
        "for col in [col for col in main_df.columns if col not in ['is_val']]: \n",
        "  if main_df[col].count() > 0:\n",
        "    pass\n",
        "  else:\n",
        "    emp_cols.append(col)\n",
        "\n",
        "print(len(fix_cols))\n",
        "print(len(emp_cols))\n",
        "print(main_df.info())\n",
        "\n",
        "def getDuplicateColumns(df): \n",
        "  duplicateColumnNames = set() \n",
        "  duplicateColumnDict = dict() \n",
        "  for x in range(df.shape[1]):\n",
        "    col = df.iloc[:,x]\n",
        "    for y in range (x+1, df.shape[1]):\n",
        "      otherCol = df.iloc[:,y]\n",
        "      if col.equals(otherCol):\n",
        "        duplicateColumnNames.add(df.columns.values[y])\n",
        "        duplicateColumnDict[df.columns[x]] = df.columns[y]\n",
        "  return list(duplicateColumnNames), duplicateColumnDict\n",
        "\n",
        "dupColNames, dupColDict = getDuplicateColumns(main_df)\n",
        "\n",
        "for key, value in dupColDict.items():\n",
        "  print(\"key={}, value = {}\".format(key, value)) \n",
        "dropcols = list()\n",
        "\n",
        "dropcols.extend([x for x in fix_cols if x not in dropcols]) \n",
        "dropcols.extend([x for x in emp_cols if x not in dropcols]) \n",
        "dropcols.extend([x for x in dupColNames if x not in dropcols]) \n",
        "print(dropcols)\n",
        "\n",
        "main_df.drop(columns= dropcols, axis=1, inplace=True)\n",
        "\n",
        "var_df = var_df[var_df['name'].isin(list(main_df.columns) + list(df_y.columns)) == True]"
      ],
      "metadata": {
        "id": "H7IB_XmmKfPV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Decided to fill all categorical NaN values with NA category. \n",
        "df_y_final = df_y[['is_sale', 'is_val']]\n",
        "print(df_y_final['is_val'].value_counts())\n",
        "\n",
        "main_df.drop(columns = ['featx'], inplace=True)\n",
        "\n",
        "print(main_df.dtypes.astype(str).value_counts())\n",
        "\n",
        "date_cols = list(main_df.select_dtypes(include = ['datetime64']).columns)\n",
        "\n",
        "num_cols = list(main_df.select_dtypes(include = ['float', 'int', 'int64', 'Float64', 'Int64', 'float64']).columns)\n",
        "cat_cols = list(main_df.select_dtypes(exclude = ['float', 'int', 'int64', 'Float64', 'Int64', 'float64', 'datetime64']).columns) \n",
        "\n",
        "num_cols.remove('is_val')\n",
        "\n",
        "main_df.drop(columns = date_cols, axis=1, inplace=True)\n",
        "\n",
        "print(len(num_cols)) \n",
        "print(len(date_cols))\n",
        "print(len(cat_cols))\n",
        "\n",
        "main_df1 = main_df.iloc[:500000,]\n",
        "main_df2= main_df.iloc[500000:,]\n",
        "print(main_df2.info())\n",
        "#!! category dtype do not let you replace or fill np.nan's with new category value, that is why i switched to str type \n",
        "#divided df into 2 as it was having memory error\n",
        "for col in cat_cols:\n",
        "  main_dfl[col] = main_dfl[col].astype('object')\n",
        "  main_dfl[col] = main_df1[col].replace(np.nan, 'NA')\n",
        "\n",
        "for col in cat_cols:\n",
        "  main_df2[col] = main_df2[col].astype('object') \n",
        "  main_df2[col] = main_df2[col].replace(np.nan, 'NA')\n",
        "\n",
        "main_df = main_dfl.append(main_df2, ignore_index = True)\n",
        "print(main_df.dtypes.astype(str).value_counts())"
      ],
      "metadata": {
        "id": "rD9JxRYqKfTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(main_df['is_val'].value_counts())\n",
        "val_x = main_df [main_df['is_val']==1]\n",
        "outsamp_df = main_df[main_df['is_val']==2] \n",
        "main_df = main_df[main_df['is_val']==0]\n",
        "\n",
        "val_y = df_y_final[df_y_final['is_val']==1] \n",
        "outsamp_y= df_y_final[df_y_final['is_val']==2] \n",
        "df_y_final = df_y_final[df_y_final['is_val']==0]\n",
        "\n",
        "print(df_y_final['is_val'].value_counts())\n",
        "\n",
        "val_x.reset_index(drop=True, inplace=True) \n",
        "main_df.reset_index(drop=True, inplace=True)\n",
        "outsamp_df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "val_y.reset_index(drop=True, inplace=True) \n",
        "df_y_final.reset_index(drop=True, inplace=True) \n",
        "outsamp_y.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(main_df['is_val'].value_counts()) \n",
        "print(df_y_final['is_val'].value_counts()) \n",
        "print(outsamp_y['is_val'].value_counts())\n",
        "\n",
        "main_df.drop(columns = ['is_val'], inplace=True) \n",
        "val_x.drop(columns = ['is_val'], inplace=True) \n",
        "outsamp_df.drop(columns = ['is_val'], inplace=True)\n",
        "\n",
        "df_y_final.drop(columns = ['is_val'], inplace=True) \n",
        "val_y.drop(columns = ['is_val'], inplace=True) \n",
        "outsamp_y.drop(columns = ['is_val'], inplace=True)"
      ],
      "metadata": {
        "id": "dUllKymSKfW5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This part is used to eliminate numerical columns that lead to multicolliunearity. If a pair is found to have higher corr value than threshold, the one having more cumulative \n",
        "# correlation with others is eliminated (Only for input data)\n",
        "from statistics import mean\n",
        "\n",
        "def get_redundant_pairs(df):\n",
        "  pairs_to_drop = set()\n",
        "  cols = df.columns\n",
        "  for i in range(0,df.shape[1]):\n",
        "    for j in range(0,i+1):\n",
        "      pairs_to_drop.add((cols[i], cols[j]))\n",
        "  return pairs_to_drop\n",
        "\n",
        "def get_triangle(df):\n",
        "  au_corr = df.corr().abs().unstack()\n",
        "  labels_to_drop = get_redundant_pairs(df)\n",
        "  au_corr = au_corr.drop(labels=labels_to_drop)\n",
        "  #print (au_corr)\n",
        "  au_corr = au_corr.sort_values (ascending=False)\n",
        "  return au_corr\n",
        "\n",
        "left_cols = num_cols.copy()\n",
        "corr_cols = []\n",
        "elim_rows = []\n",
        "mean_dict = {}\n",
        "\n",
        "row = 0\n",
        "while get_triangle(main_df[left_cols])[0:1].values > script_pars['dropcor_thresh']:\n",
        "\n",
        "  #print (len(left_cols))\n",
        "  sub_df = get_triangle(main_df[left_cols])\n",
        "  filter_df_1 = [t for t in sub_df.index if (t[0] == sub_df.index[0][0]) or (t[1] == sub_df.index[0][0])] \n",
        "  filter_df_2 = [t for t in sub_df.index if (t[0] == sub_df.index[0][1]) or (t[1] == sub_df.index[0][1])] \n",
        "  #print(np.nanmean(sub_df[filter_df_1].values))\n",
        "  if np.nanmean(sub_df[filter_df_1].values) > np.nanmean(sub_df[filter_df_2].values):\n",
        "    corr_cols.append(sub_df[0:1].index[0][0]) \n",
        "    left_cols.remove(sub_df[0:1].index[0][0])\n",
        "  else:\n",
        "    corr_cols.append(sub_df[0:1].index[0][1])\n",
        "    left_cols.remove(sub_df[0:1].index[0][1])\n",
        "  elim_rows.append(sub_df[0:1])\n",
        "  mean_dict[row]=[(sub_df[0:1].index[0][0], np.nanmean(sub_df[filter_df_1].values)), (sub_df[0:1].index[0][1], np.nanmean(sub_df[filter_df_2].values))] \n",
        "  row = row + 1\n",
        "  #print(len(left_cols))\n",
        "\n",
        "print(corr_cols)\n",
        "print(elim_rows)\n",
        "print(mean_dict)"
      ],
      "metadata": {
        "id": "2O28C90qQJe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = [x for x in num_cols if x not in corr_cols]\n",
        "#print(sub_df[sub_df.apply(lambda x: 'featxx' in x)])\n",
        "print(num_cols)"
      ],
      "metadata": {
        "id": "ZePM4e3JQJh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_df.drop(corr_cols, axis=1, inplace=True) \n",
        "outsamp_df.drop(corr_cols, axis=1, inplace=True)\n",
        "val_x.drop(corr_cols, axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "ZYb2HtY8QJkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# These 5 fields below is for calculating cramers_v scores between categorical variables. So that we can define correlated categorical ones, and eliminate if needed. \n",
        "column_headers = [cat_cols[x].split()[-1] for x in range(len(cat_cols))] \n",
        "print(column_headers)\n",
        "\n",
        "main_df_cramer = main_df.copy()\n",
        "\n",
        "def gnumeric_func(data, columns):\n",
        "  data[columns] = data[columns].apply(lambda x: pd.factorize(x)[0])\n",
        "  # return data\n",
        "\n",
        "gnumeric_func(main_df_cramer, column_headers)"
      ],
      "metadata": {
        "id": "in32IjihQJnt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import chi2_contingency\n",
        "from scipy.stats import chi2\n",
        "import pandas as pd\n",
        "final_df= pd.DataFrame(columns=('column1', 'column2', 'cramers_V')) \n",
        "#Due to memory issues, set these to 100k\n",
        "\n",
        "def cramers_v(x,y, main_df_cramer):\n",
        "\n",
        "  \"\"\"\n",
        "  x and y are 2 columns to be compared related to cramer's score\n",
        "  main_df_cramer is calculated with above gnumeric_func, and it is used here\n",
        "  \"\"\"\n",
        "  confusion_matrix = pd.crosstab(main_df_cramer[x].iloc[:100000],main_df_cramer[y].iloc[:100000])\n",
        "  chi2 = chi2_contingency(confusion_matrix)[0]\n",
        "  n = confusion_matrix.sum().sum()\n",
        "  phi2 =chi2/n\n",
        "  r, k = confusion_matrix.shape\n",
        "  phi2corr = max(0,phi2-((k-1)*(r-1))/(n-1))\n",
        "  rcorrr = r -((r-1)**2)/(n-1)\n",
        "  kcorr = k-((k-1)**2)/(n-1)\n",
        "  return np.sqrt(phi2corr/min((kcorr-1), (rcorr-1)))\n",
        "i = 0\n",
        "\n",
        "used_cols = []\n",
        "\n",
        "for col1 in column_headers:\n",
        "  if (col1 !='on_off') & (col1 not in used cols):\n",
        "    #print(col1)\n",
        "    used_cols.append(col1) \n",
        "    #print (used_cols)\n",
        "    \n",
        "    for col2 in column_headers:\n",
        "      if (col2 !='on_off' and col1!=col2) & (col2 not in used_cols):\n",
        "        x = cramers_v(col1, col2, main_df_cramer)\n",
        "        final_df.loc[i]=[col1, col2,x]\n",
        "        i=i+1\n"
      ],
      "metadata": {
        "id": "zpbzmZgbQJqh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot\n",
        "%matplotlib inline\n",
        "\n",
        "# plt.imshow(final_df, cmap='hot', interpolation='nearest')\n",
        "# plt.show()\n",
        "\n",
        "#final_df.plot(x='c1')\n",
        "temp_df= final_df.pivot(index='columnl', columns='column2', values='cramers_V') \n",
        "pyplot.figure(figsize=(20,20))\n",
        "hm=sns.heatmap(temp_df, vmin=0, vmax=1, linewidths=0.1)\n",
        "\n",
        "hm.figure.savefig(\"output.png\")\n"
      ],
      "metadata": {
        "id": "7R9UZ2dGQJtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(main_df_cramer[used_cols].nunique())\n",
        "uniq_df = pd.DataFrame(main_df_cramer[used_cols].nunique(), columns = ['uniq_cnt']) \n",
        "uniq_df.reset_index(inplace=True)\n",
        "uniq_df = uniq_df.rename(columns = {'index':'name'})\n",
        "print(uniq_df)"
      ],
      "metadata": {
        "id": "fW5hBWflUXIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_merged = pd.merge(final_df, uniq_df,left_on = 'column1', right_on='name', how='left') \n",
        "final_merged = final_merged.drop(columns = ['name'])\n",
        "final_merged = final_merged.rename(columns = {'uniq_cnt': 'uniq_cnt_left'})\n",
        "\n",
        "final_merged2 = pd.merge(final_merged, uniq_df, left_on = 'column2', right_on = 'name', how='left') \n",
        "final_merged2 = final_merged2.drop(columns = ['name'])\n",
        "#print(final_merged2)\n",
        "final_merged2.sort_values(by=['cramers_V', 'column1'], ascending=False).iloc[:50]"
      ],
      "metadata": {
        "id": "je2q2rs0UXLZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_conn_df = main_df.loc[:,'conn_id']\n",
        "outsamp_conn_df = outsamp_df.loc[:, 'conn_id']\n",
        "val_conn_df = val_x.loc[:,'conn_id']\n",
        "\n",
        "main_df.drop(columns = ['conn_id'], axis=1, inplace=True) \n",
        "outsamp_df.drop(columns=['conn_id'], axis=1, inplace=True) \n",
        "val_x.drop(columns = ['conn_id'], axis=1, inplace=True)\n",
        "\n",
        "cat_cols.remove('conn_id')"
      ],
      "metadata": {
        "id": "sZSQsWldUXOL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if script_pars['feature_selection'] == 1:\n",
        "  from sklearn.tree import DecisionTreeClassifier\n",
        "  from sklearn.inspection import permutation_importance\n",
        "  # IF YOU WILL USE PERMUTATION IMP INSIDE RFECV YOU NEED TO GET ELIS VERSION. IT IS SUITABLE, NOT SKLEARN VERSION \n",
        "  #from eli5.sklearn import PermutationImportance\n",
        "  from sklearn.linear_model import LogisticRegression\n",
        "  from sklearn.pipeline import Pipeline\n",
        "  from sklearn.compose import ColumnTransformer\n",
        "  from sklearn.preprocessing import LabelEncoder, OrdinalEncoder, MinMaxScaler\n",
        "  from sklearn.feature_selection import RFECV\n",
        "  from lightgbm import LGBMClassifier\n",
        "  from sklearn.feature_selection import mutual_info_classif\n",
        "  from sklearn.feature_selection import Generic UnivariateSelect\n",
        "\n",
        "  dt = DecisionTreeClassifier(random_state = 0)\n",
        "  lr = LogisticRegression()\n",
        "  lgb = LGBMClassifier(random_state = 23, max_depth = 6, n_estimators = 300)\n",
        "\n",
        "  main_df_copy = main_df.copy()\n",
        "\n",
        "  #check it, it may not work as expected\n",
        "  main_df_copy[cat_cols] = main_df_copy[cat_cols].replace(np.nan, 'NULL')\n",
        "\n",
        "\n",
        "  orden = OrdinalEncoder()\n",
        "  main_df_copy[cat_cols]= orden.fit_transform(main_df_copy[cat_cols])\n",
        "  main_df_copy[num_cols] = main_df_copy[num_cols].fillna(main_df_copy[num_cols].median())\n",
        "\n",
        "  ###It will be used if permutation feature importance is needed to applied into pipeline \n",
        "  #pi = PermutationImportance (dt, cv=4, random_state = 0)\n",
        "\n",
        "  #rfecv has a problem with pipeline recognition\n",
        "  #cat_transformer = Pipeline(steps = [('enc', OrdinalEncoder())])\n",
        "  #num_transformer = Pipeline(steps = [('scl', MinMaxScaler (feature_range = (0,1)))])\n",
        "  #preprocessor = ColumnTransformer (transformers = [('cat', 'passthrough', cat_cols), ('num', 'passthrough', num_cols)], remainder = 'passthrough')\n",
        "\n",
        "  #all_pipe = Pipeline(steps = [('prep', preprocessor), ('est', lgb)])\n",
        "\n",
        "  #rfe = RFECV(estimator = pi, cv = 4, min_features_to_select = 80, scoring = 'roc_auc', step = 1, n_jobs =12)\n",
        "  rfe = RFECV(estimator = dt,cv = 4, min_features_to_select = script_pars['rfecv_min_feat'], scoring = 'roc_auc', step = 1, n_jobs =16) \n",
        "  rfe.fit(main_df_copy, df_y_final)\n",
        "\n",
        "  \"\"\"\n",
        "  mutual_inf = mutual_info_classif (main_df, df_y_final, random_state = 10)\n",
        "  generic = GenericUnivariateSelect(score_func = mutual_info_classif, mode = 'k_best', param=100) \n",
        "  main_df_trans = generic.fit_transform(main_df, df_y_final)\n",
        "  print(main_df['var8'][main_df['var8'].isnull()])\n",
        "  \"\"\"\n",
        "\n",
        "  ### This part is to restructure num and cat cols after elimination of first part features\n",
        "\n",
        "  main_df_copy[cat_cols] = orden.inverse_transform(main_df_copy[cat_cols])\n",
        "  cols_left = main_df_copy.columns[rfe.get_support()].values\n",
        "\n",
        "  main_df = pd.DataFrame(main_df, columns= cols_left)\n",
        "  outsamp_df = pd.DataFrame(outsamp_df, columns = cols_left) \n",
        "  val_x = pd.DataFrame(val_x, columns = cols_left)\n",
        "\n",
        "  num_vars= num_cols.copy()\n",
        "  num_cols = []\n",
        "  cat_vars= cat_cols.copy() \n",
        "  cat_cols = []\n",
        "\n",
        "  for col in cols_left:\n",
        "    if col in cat_vars:\n",
        "      main_df [col] = main_df [col].astype('object') \n",
        "      cat_cols.append(col)\n",
        "    else:\n",
        "      pass\n",
        "\n",
        "  for col in cols_left:\n",
        "    if col in num_vars:\n",
        "      main_df [col] = main_df [col].astype('float') \n",
        "      num_cols.append(col)\n",
        "    else:\n",
        "      pass\n",
        "  print(num_cols) \n",
        "  print(cat_cols)\n",
        "\n",
        "if script_pars['feature_selection'] == 0:\n",
        "  cat_cols = ['feata', 'featb', 'featc']\n",
        "  num_cols = ['featd', 'feate featf'] \n",
        "  \n",
        "  cols_left = cat_cols + num_cols\n",
        "\n",
        "  main_df = pd.DataFrame(main_df, columns= cols_left)\n",
        "  outsamp_df = pd.DataFrame(outsamp_df, columns = cols_left)\n",
        "  val_x = pd.DataFrame(val_x, columns = cols_left)\n",
        "\n",
        "  num_vars = num_cols.copy()\n",
        "  num_cols = []\n",
        "  cat_vars= cat_cols.copy()\n",
        "  cat_cols = []\n",
        "\n",
        "  for col in cols_left:\n",
        "    if col in cat_vars:\n",
        "      main_df [col] = main_df[col].astype('object') \n",
        "      cat_cols.append(col)\n",
        "    else:\n",
        "      pass\n",
        "  for col in cols_left:\n",
        "    if col in num_vars:\n",
        "      main_df [col] = main_df[col].astype('float') \n",
        "      num_cols.append(col)\n",
        "    else:\n",
        "      pass"
      ],
      "metadata": {
        "id": "_c5dwA_gUXQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def col_ind_get(prep, all cols, num_cols, cat_cols, enc_cols):\n",
        "  \"\"\"\n",
        "  This function looks at the structure of Pipeline transformation, and determines which features and feature indices are related to which pipeline sub process\n",
        "  It looks at the preprocessor instance, which is a column transformer consisting of cat and numerical transformers\n",
        "  I am still not sure about enc_cols parameter, i forgot why i added it. But it is sth like encoded variables, will not be encoded etc.\n",
        "  Below you are seeing transformers i 2, which retrieves which column is used for which transformer.\n",
        "  Aim of this function is to keep order of columns after transformation, preprocessing. It will keep ordered names and indices, and it will be helpful for reverse transformation after onehot etc \n",
        "  \"\"\"\n",
        "  pre_all_cols = []\n",
        "  pre_cat_cols = []\n",
        "  pre_cat_ind = []\n",
        "\n",
        "  cat_colss = list(set(cat_cols) - set(enc_cols))\n",
        "\n",
        "  for i in range(len(prep.transformers)):\n",
        "    pre_all_cols.extend(prep.transformers[i][2])\n",
        "\n",
        "  pre_cat_cols = [item for item in pre_all_cols if item in cat_colss]\n",
        "  pre_cat_ind = [i for i in range(len(pre_all_cols)) if pre_all_cols[i] in cat_colss] \n",
        "  pre_num_cols = [item for item in pre_all_cols if item in num_cols]\n",
        "  pre_num_ind = [i for i in range(len(pre_all_cols)) if pre_all_cols[i] in num_cols]\n",
        "\n",
        "  return pre_all_cols, pre_cat_cols, pre_cat_ind, pre_num_cols, pre_num_ind"
      ],
      "metadata": {
        "id": "0dPKnJUoUXTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "run_date = datetime.now().strftime(\"%y%m%d%H%M\")\n",
        "\n",
        "best_results = dict() \n",
        "best_params = dict() \n",
        "best_models= dict()\n",
        "best_summary = dict()"
      ],
      "metadata": {
        "id": "DBGPViWXUXWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from feature_engine.imputation import Categorical Imputer, MeanMedian Imputer\n",
        "from feature_engine.encoding import RareLabelEncoder\n",
        "from lightgbm import LGBMClassifier\n",
        "import pickle\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import SGDClassifier, Logistic Regression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from category_encoders.leave_one_out import LeaveOneOutEncoder\n",
        "\n",
        "ordered_cols = cat_cols + num_cols\n",
        "\n",
        "main_df2 = main_df.reindex(columns = ordered_cols)\n",
        "outsamp_df = outsamp_df.reindex(columns = ordered_cols)\n",
        "val_x = val_x.reindex (columns=ordered_cols)\n",
        "\n",
        "df_y_final[script_pars['target']] = df_y_final[script_pars['target']].astype('int') \n",
        "outsamp_y[script_pars['target']] = outsamp_y[script_pars['target']].astype('int') \n",
        "val_y[script_pars['target']] = val_y[script_pars['target']].astype('int')\n",
        "####!!!!! Why i was using enc_cols!!!!!!11\n",
        "enc_cols = []\n",
        "\n",
        "\n",
        "models = dict() \n",
        "\n",
        "paramslogi = {}\n",
        "\n",
        "paramsrfc = {\n",
        "  'est_rfc_max_depth': [11,21,31],\n",
        "  'est_rfc_n_estimators': [25,75,150],\n",
        "  'est_rfc_min_samples_split': np.linspace(0.1, 0.9, 3, endpoint = True),\n",
        "  'est_rfc_verbose': [1],\n",
        "  'est_rfc_random_state': [35],\n",
        "  'est_rfc_n_jobs': [16]\n",
        "  #'est_min_samples_leaf': np. linspace (0.1, 0.5, 3, endpoint = True)\n",
        "  }\n",
        "\n",
        "paramsgnb = {\n",
        "  }\n",
        "\n",
        "paramsxgbc = {\n",
        "  'est_xgbc_n_estimator': [25,75,150],\n",
        "  'est_xgbc_max_depth': [11,21,31],\n",
        "  'est_xgbc_learning_rate': [0.0001, 0.001],\n",
        "  'est_xgbc_random_state': [35],\n",
        "  'est_xgbc_verbosity': [1],\n",
        "  'est_xgbc_n_jobs': [8]\n",
        "  }\n",
        "\n",
        "paramsknnc = {\n",
        "  'est_knn_n_neighbors': [3,5,8]\n",
        "  }\n",
        "\n",
        "paramssgdc = {\n",
        "  'est_sgdc_penalty': ['l1', 'l2', 'elasticnet'],\n",
        "  'est_sgdc_max_iter': np.linspace (100,700, 3, endpoint=True, dtype = 'int'),\n",
        "  'est_sgdc_alpha': [0.0001, 0.001],\n",
        "  'est_sgdc_loss': ['log_loss'],\n",
        "  'est_sgdc_random_state': [35],\n",
        "  'est_sgdc_n_jobs': [16]\n",
        "  }\n",
        "\n",
        "paramslgb = {\n",
        "  'est_lgb_max_depth': [11,21, 31],\n",
        "  'est_lgb_learning_rate': [0.001,0.0001],\n",
        "  'est_lgb_n_estimators': [25, 75, 150],\n",
        "  'est_lgb_num_leaves': np.linspace (11,91,3, endpoint=True, dtype = int),\n",
        "  'est_lgb_verbosity': [1],\n",
        "  'est_lgb_random_state': [35],\n",
        "  'est_lgb_n_jobs': [16]\n",
        "  }\n",
        "\n",
        "paramssvc = {\n",
        "  'est_svc_C': [1,10,100],\n",
        "  'est_svc_kernel': ['linear', 'rbf'],\n",
        "  'est_svc_tol': [0.0001, 0.001]\n",
        "  }\n",
        "\n",
        "models['lgb'] = [LGBMClassifier(), paramslgb]\n",
        "models['rfc'] = [RandomForestClassifier(), paramsrfc]\n",
        "##models['knn'] = [KNeighborsClassifier (algorithm = 'kd_tree', n_jobs=16), paramsknnc]\n",
        "models['gnb'] = [GaussianNB(), paramsgnb]\n",
        "models['sgdc'] = [SGDClassifier(), paramssgdc]\n",
        "models['logi'] = [LogisticRegression (random_state= 35, n_jobs = 16), paramslogi]\n",
        "models['xgbc'] = [XGBClassifier (tree_method = 'hist', objective = 'binary: logistic'), paramsxgbc] \n",
        "##models['svc'] = [SVC (verbose= 1, random_state= 35, probability = True), paramssvc] very slow\n",
        "\n",
        "for key, value in models.items():\n",
        "  start_time = timeit.default_timer()\n",
        "  scorer = ['roc_auc', 'accuracy', 'f1', 'jaccard']\n",
        "  ### !!!! IDEA FOR MISSING VALUE HANDLING: If a row has missing values for columns like 10% of all, as a threshold. Drop it. Such an idea can be applied before the undersampling process \n",
        "  numeric_transformer = Pipeline(steps = [('Mimp', MeanMedianImputer(imputation_method = 'median', variables = num_cols)), \n",
        "                                          ('scl', MinMaxScaler (feature_range = (0,1)))])\n",
        "  # since gaussiannb doesnt want a sparse matrix\n",
        "  if key 'gnb':\n",
        "    categoric_transformer = Pipeline(steps = [('Cimp', CategoricalImputer(imputation_method = 'missing', fill_value = 'NA', variables = cat_cols)), \n",
        "                                              ('rare', RareLabelEncoder(tol = 0.01, n_categories = 3, replace_with = 'rare', variables = cat_cols)), \n",
        "                                              #('Loo', LeaveOneOutEncoder(sigma = 0.1, cols = cat_cols))])\n",
        "                                              ('hot', OneHotEncoder(handle_unknown = 'ignore', sparse = False))])\n",
        "\n",
        "  else:\n",
        "    categoric_transformer = Pipeline(steps = [('Cimp', CategoricalImputer(imputation_method = 'missing', fill_value = 'NA', variables = cat_cols)), \n",
        "                                              ('rare', RareLabelEncoder(tol = 0.01, n_categories = 3, replace with = 'rare', variables = cat_cols)), \n",
        "                                              #('Loo', LeaveOneOutEncoder(sigma = 0.1, cols = cat_cols))]) \n",
        "                                              ('hot', OneHotEncoder(handle_unknown = 'ignore', sparse = True))])\n",
        "\n",
        "  preprocessor = ColumnTransformer(transformers = [('cat', categoric_transformer, cat_cols),\n",
        "                                                  ('num', numeric_transformer, num_cols)], remainder = 'passthrough')\n",
        "  all_pipe = Pipeline(steps = [('prep', preprocessor), (str('est '+key), value[0])])\n",
        "\n",
        "  pre_all_cols, pre_cat_cols, pre_cat_ind, pre_num_cols, pre_num_ind = col_ind_get(preprocessor, main_df2.columns, num_cols, cat_cols, enc_cols) \n",
        "  search_space = value[1]\n",
        "\n",
        "  #print(pre_all_cols) \n",
        "  #print(pre_cat_cols)\n",
        "  #print(pre_cat_ind)\n",
        "  #print(pre_num_cols)\n",
        "  #print(pre_num_ind)\n",
        "  #print(list(main_df2.columns))\n",
        "  #print(main_df2.columns)\n",
        "  #print(main_df2.head(2))\n",
        "\n",
        "  #for col in cat_cols:\n",
        "  # print(col)\n",
        "  # print(main_df2.loc[:, col].value_counts())\n",
        "  #print(main_df2[num_cols].info())\n",
        "  #print(df_y_final.head(5))\n",
        "\n",
        "  ###Using pipeline inside GridSearch is very critical!!!!!!!!!!, it only fits preprocessing on train folds in this structure\n",
        "\n",
        "  ### When you want to run whole data with best parameters found, you can use refit = True\n",
        "  ### But like here, when there are multiple scorers, you define one scorer here, to define best model and hyperparameters according to this metric \n",
        "  ### For a cv of 5, you will have 5 accuracy and 5 roc scores for both train and test. k=1 may have highest mean accuracy, but k=5 may have roc \n",
        "  ### So, you are decidin to use refit variable as decider. And fitting whole data according to that. Getting best model out of it as best estimator \n",
        "  ### So, you may not need to fit all dataset again, if you have best estimator here!!!!!!!!! !!!\n",
        "  ### THIS BEST ESTIMATOR will enable you to use PREDICT and PREDICT_PROBA etc.\n",
        "  grid_search= GridSearchCV(all pipe, search_space, cv= 5, verbose= 1, refit = 'roc_auc', scoring scorer, return_train_score = True, n_jobs=16)\n",
        "\n",
        "  # this version is used for CatBoost, when we give it cat features automatically it handles them. But now we are using mixed algos, and already preprocessed data \n",
        "  #grid_search.fit(main_df2, y=df_y_final, est_cat_features=pre_cat_ind)\n",
        "  grid_search.fit(main_df2, y=df_y_final)\n",
        "\n",
        "  ind = grid_search.best_index_\n",
        "  print(\"model = {}\".format(key))\n",
        "  print(\"train_roc = {}, test_roc = {}\".format(grid_search.cv_results_['mean_train_roc_auc'][ind], grid_search.cv_results_['mean_test_roc_auc'][ind])) \n",
        "  print(\"train_accuracy {}, test_accuracy = {}\".format(grid_search.cv_results_['mean_train_accuracy'][ind], grid_search.cv_results_['mean_test_accuracy'][ind])) \n",
        "  print(\"train_f1 = {}, test_f1 = {}\".format(grid_search.cv_results_['mean_train_f1'][ind], grid_search.cv_results ['mean_test_f1'][ind]))\n",
        "  print(\"train_jaccard = {}, test_jaccard = {}\".format(grid_search.cv_results_['mean_train_jaccard'][ind], grid_search.cv_results_['mean_test_jaccard'][ind])) \n",
        "  print(\"avg_fit_time = {}\".format(grid_search.cv_results_['mean_fit_time'][ind]))\n",
        "  print(\"best_params = {}\".format(grid_search.best_params_))\n",
        "  print(\"best_estimator = {}\".format(grid_search.best_estimator_.named_steps[str('est_'+key)]))\n",
        "  #print(\"---0.1f minutes---\") %((timeit.default_timer()-start_time)/60)\n",
        "  print(\"run_start = {}...\".format(start_time))\n",
        "  print(\"current_time = {}...\".format(datetime.now()))\n",
        "\n",
        "  final_list = []\n",
        "  ### Print also the foldwise train and test scores, apart from mean values. To see if it has high STD error\n",
        "  ### std_train_score str_train_roc_auc std_test_roc_auc mean_fit_time std_fit_time mean_score_time std_score_time\n",
        "  best_params[key] = grid_search.best_params_\n",
        "  final_list.append(grid_search.best_params_)\n",
        "\n",
        "  best_results[key] = [grid_search.cv_results_['mean_test_roc_auc'][ind], grid_search.cv_results_['mean_test_accuracy'][ind], grid_search.cv_results_['mean_test_f1'][ind], \n",
        "                       grid_search.cv_results_['mean_test_jaccard'][ind]] \n",
        "  final_list.append([grid_search.cv_results_['mean_test_roc_auc'][ind], grid_search.cv_results_['mean_test_accuracy'][ind],\n",
        "                      grid_search.cv_results_['mean_test_f1'][ind], grid_search.cv_results_['mean_test_jaccard'][ind]])\n",
        "  \n",
        "  best_models [key] = grid_search.best_estimator_\n",
        "  final_list.append(grid_search.best_estimator_)\n",
        "\n",
        "  best_summary[key] = final_list\n",
        "  with open(os.getcwd()+\"/model_results/backup/\" + run_date + \"-\" + key + \".pkl\", 'wb') as f:\n",
        "    pickle.dump(best_summary[key][2], f)\n",
        "\n",
        "  \"\"\"\n",
        "  importances = grid_search.best_estimator_.named_steps['est'].feature_importances_ \n",
        "  importances = [float(i) for i in importances]\n",
        "\n",
        "  print(pre_all_cols)\n",
        "  print(importances)\n",
        "  print(list(zip(pre_all_cols, importances)))\n",
        "  \"\"\""
      ],
      "metadata": {
        "id": "0kloObN2UXY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "os.mkdir(os.getcwd()+\"/model_results/\" + run_date + \"-\" + script_pars['run_type'])\n",
        "\n",
        "for key, value in best_summary.items():\n",
        "  with open(os.getcwd()+\"/model_results/\" + run_date + \"-\" + script_pars['run_type']+ \"/\" + key + \".pkl\", 'wb') as f: \n",
        "    pickle.dump(best_summary[key][2], f)"
      ],
      "metadata": {
        "id": "_0hciSACiHRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_success_df = pd.DataFrame(columns = ['model', 'auc_score', 'accuracy_score', 'fl_score', 'jaccard_score']) \n",
        "best_summary_copy = best_summary.copy()\n",
        "\n",
        "### check all list operations, list = another_list doesnt work, it binds each. Doesnt create an independent list \n",
        "for key, value in best_summary.items():\n",
        "  print(best_summary[key][1])\n",
        "  temp_list = best_summary[key][1][:] \n",
        "  print(temp_list)\n",
        "  temp_list.insert(0, str(key))\n",
        "  print(temp_list)\n",
        "  model_success_df.loc[len(model_success_df)] = temp_list\n",
        "\n",
        "model_success_df['auc_rank'] = model_success_df['auc_score'].rank(ascending = False, method = 'min')\n",
        "model success_df['accuracy_rank'] = model_success_df['accuracy_score'].rank(ascending = False, method = 'min') \n",
        "model_success_df['f1_rank'] = model_success_df['f1_score'].rank(ascending = False, method = 'min')\n",
        "model_success_df['jaccard_rank'] = model_success_df['jaccard_score'].rank (ascending = False, method = 'min')\n",
        "model_success_df['overall_total_rank'] = model_success_df['auc_rank'] + model_success_df['accuracy_rank'] + model_success_df['f1_rank']# + model_success_df['jaccard_rank\"] \n",
        "model_success_df['overall_rank'] = model_success_df['overall_total_rank'].rank(ascending = True, method = 'min')\n",
        "model_success_df = model_success_df.sort_values(['overall_rank', 'accuracy_score', 'fl_score'], ascending [True, False, False]).reset_index() \n",
        "print(model_success_df)"
      ],
      "metadata": {
        "id": "-PtLfsVJiHUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_n_models = script_pars['top_n_models']\n",
        "\n",
        "voter_models = model_success_df['model'].iloc[:top_n_models].unique()\n",
        "voter_models.sort()\n",
        "print(voter_models)"
      ],
      "metadata": {
        "id": "JDS5DcHWiHXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "preferred_folder_name = script_pars['preferred_folder_name']\n",
        "\n",
        "if preferred_folder_name == '':\n",
        "\n",
        "  #model_dirs = [x[0] for x in os.walk (os.getcwd())]\n",
        "  model_dirs = glob(os.getcwd()+\"/model_results/*/\", recursive = True)\n",
        "  model_dirs_filtered = [x for x in model_dirs if script_pars['run_type'] in x]\n",
        "  model_dirs_filtered.sort(reverse = True)\n",
        "  model_dir = model_dirs_filtered[0]\n",
        "\n",
        "  model_list = [s for s in os.listdir(model_dir) if any(x in s for x in voter_models)]\n",
        "\n",
        "  elif preferred_folder_name != '':\n",
        "    model_dir = os.getcwd() + \"/model_results/\" + preferred_folder_name + \"/\"\n",
        "\n",
        "  model_list = [s for s in os.listdir(model_dir) if any (x in s for x in voter_models)]"
      ],
      "metadata": {
        "id": "yNvVij21iHaT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_res_dict = {}\n",
        "model_res_dict['columns'] = model_success_df.columns\n",
        "for i in model_success_df.index:\n",
        "  model_res_dict[i] = model_success_df.iloc[i,:]\n",
        "\n",
        "  with open(model_dir+\"/voting_results.txt\", 'w') as f:\n",
        "    print(model_res_dict, file = f)\n",
        "\n",
        "  with open(model_dir+\"/voting_results.pkl\", 'wb') as fp:\n",
        "    pickle.dump(model_res_dict, fp)\n",
        "    print('dictionary saved successfully to file')\n",
        "  \n",
        "  with open(model_dir+\"/voting_df.pkl\", 'wb') as fp:\n",
        "    pickle.dump(model_success_df, fp)\n",
        "    print('dictionary saved successfully to file')"
      ],
      "metadata": {
        "id": "m1TBtkrmiHq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = []\n",
        "for i in range(len(model_list)):\n",
        "  with open(model_dir+\"/\"+model_list[i], 'rb') as f:\n",
        "    model =  pickle.load(f)\n",
        "    models.append(model)"
      ],
      "metadata": {
        "id": "ZUkco3jgmGB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_list)\n",
        "print(model_dirs)\n",
        "print(model_dirs_filtered) \n",
        "print(model_dir)"
      ],
      "metadata": {
        "id": "OKiAqfR7mGFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = pd.DataFrame()\n",
        "for i in range(len(models)):\n",
        "  predictions['proba' + str(i)] = models[i].predict_proba(main_df2)[:,1]\n",
        "  predictions['predict' + str(i)] = models[i].predict(main_df2)"
      ],
      "metadata": {
        "id": "1Yf6dtnumGIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions['avg_proba'] = predictions[[col for col in predictions.columns if 'proba' in col]].mean(axis=1)\n",
        "predictions['voted_is_sale'] = np.where(predictions[[col for col in predictions.columns if 'predict' in col]].sum(axis=1)/len(models) <0.5, 0,1) \n",
        "predictions = predictions.join(df_y_final['is_sale'])\n",
        "print (predictions)"
      ],
      "metadata": {
        "id": "ezBX7p40mGLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conn_df = pd.DataFrame(main_conn_df, columns = ['conn_id'])\n",
        "print(main_conn_df)\n",
        "print(conn_df)\n",
        "predictions['conn_id'] = conn_df.loc[:,'conn_id']\n",
        "print (predictions.head())"
      ],
      "metadata": {
        "id": "-vmPPfCFmGOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_dict = {}\n",
        "cols_dict['ordered_cols'] = ordered_cols\n",
        "cols_dict['cat_cols'] = cat_cols\n",
        "cols_dict['num_cols'] = num_cols\n",
        "\n",
        "with open(model_dir+\"/columns.txt\", 'w') as f: \n",
        "  print(cols_dict, file = f)\n",
        "\n",
        "with open(model_dir+\"/columns.pkl\", 'wb') as f:\n",
        "  pickle.dump(cols_dict, f)\n",
        "  print('dictionary saved successfully to file')"
      ],
      "metadata": {
        "id": "-kcVYqDnnA4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groups_list = [10,20,40,80]\n",
        "bins_dict = {}\n",
        "\n",
        "for i in groups_list:\n",
        "\n",
        "  predictions['PropensityGroup_bin'+str(i)], bins_dict[i] = pd.qcut(predictions[\"avg_proba\"], retbins = True, q = i, labels=False)\n",
        "  predictions.groupby(['PropensityGroup_bin' + str(i)])[\"avg_proba\"].agg([\"min\",\"max\",\"count\"]).reset_index()#.to_csv(f\" thresholds_{today_date}_all.csv\", index = False)\n",
        "  #print(predictions.groupby([\"PropensityGroup_bin\" + str(i)]) [\"avg_proba\"].agg([\"min\",\"max\",\"count\"]))\n",
        "\n",
        "  bins_dict[i][0] = 0\n",
        "  bins_dict[i][-1] = 1 \n",
        "  print(bins_dict[i])"
      ],
      "metadata": {
        "id": "xRHqw9tonA8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(model_dir+\"/bins.txt\", 'w') as f: \n",
        "  print(bins_dict, file = f)\n",
        "\n",
        "with open (model_dir+\"/bins.pkl\", 'wb') as f:\n",
        "  pickle.dump(bins_dict, f)\n",
        "  print('dictionary saved successfully to file')\n",
        "\n",
        "with open(model_dir+\"/explanation.txt\", 'w') as f: \n",
        "  print(script_pars['explanation'], file = f)"
      ],
      "metadata": {
        "id": "QoOdFh6anA_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(figsize = (8,12), nrows = 4) \n",
        "fig.suptitle('Vertically stacked subplots') \n",
        "#axs[0].plot(x, y)\n",
        "#axs[1].plot(x, y)"
      ],
      "metadata": {
        "id": "rC00PbiXnBDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(groups_list)):\n",
        "  groups = predictions.groupby([\"PropensityGroup_bin\"+str(groups_list[i])])[\"is_sale\"].agg([\"count\", \"mean\"])\n",
        "  groups['mean'].plot(kind='bar', ax = axs[i])\n",
        "  #ax_str.set_ylabel('Mean')\n",
        "  #ax_str.set_xlabel('Propensity group')\n",
        "\n",
        "  plt.grid()"
      ],
      "metadata": {
        "id": "Zkilel7enBHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if ((script_pars['val_split'] == 'shuffle') and (script_pars['shuffle_test_size'] > 0)) or ((script_pars['val_split'] == 'lastN') and (script_pars['lastn_days']>0)): \n",
        "  \n",
        "  predictions_val = pd.DataFrame()\n",
        "  for i in range(len(models)):\n",
        "    predictions_val['proba' + str(i)] = models[i].predict_proba (val_x)[:,1] \n",
        "    predictions_val['predict'+str(i)] = models[i].predict(val_x)\n",
        "\n",
        "  predictions_val['avg_proba'] = predictions_val[[col for col in predictions_val.columns if 'proba' in col]].mean(axis=1)\n",
        "  predictions_val['voted_is_sale'] = np.where(predictions_val[[col for col in predictions_val.columns if 'predict' in col]].sum(axis=1)/len(models) <0.5, 0,1) \n",
        "  predictions_val = predictions_val.join(val_y['is_sale'])\n",
        "\n",
        "  conn_df_val = pd.DataFrame(val_conn_df, columns = ['conn_id']) \n",
        "  predictions_val['conn_id'] = conn_df_val.loc[:,'conn_id']\n",
        "\n",
        "  fig, axs = plt.subplots(figsize = (8,12), nrows = 4)\n",
        "  fig.suptitle('Vertically stacked subplots')\n",
        "\n",
        "  for ii in range(len(groups_list)):\n",
        "\n",
        "    predictions_val[\"PropensityGroup_bin\" +str(groups_list[ii])] = pd.cut(predictions_val[\"avg_proba\"], bins=bins_dict[groups_list[ii]], labels=False, include_lowest=True) \n",
        "    predictions_val.groupby([\"PropensityGroup_bin \"+str(groups_list[ii])])[\"avg_proba\"].agg([\"min\",\"max\", \"count\"]).reset_index()#.to_csv(f\" thresholds_{today_date}_all.csv\", index = False) \n",
        "    #print(predictions_val.groupby([\"PropensityGroup_bin\" + str(groups_list[ii])])[\"avg_proba\"].agg([\"min\",\"max\",\"count\"]))\n",
        "\n",
        "  groups_val = predictions_val.groupby([\"PropensityGroup_bin\"+str(groups_list[ii])])[\"is_sale\"].agg([\"count\",\"mean\"])\n",
        "  groups_val['mean'].plot(kind='bar', ax = axs[ii])\n",
        "  plt.grid()"
      ],
      "metadata": {
        "id": "esk8765qnBNO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### I have 2 different pipelines, i am trying best to make them parallel, going through same operations\n",
        "### But sometimes It is possible that 2 dataframes going into Fit and predict might be different\n",
        "### Difference may be dtypes, difference may be format of values, like 1-2-3 was categories\n",
        "### I saved data as csv, then read it, then i figure out that python recognized them as floats\n",
        "### Converted into a format like 1.0, 2.0, 3.0 . Even though they are converted to object dtype\n",
        "### They will be treated as unseen categories on predict pipeline. And I will see the probabilities as very low. \n",
        "### Also another sanity check below is changing one feature value at a time, and getting probabilities for them to check consistency\n",
        "### Most of the time, only one change differs proba, but not drastically. Then this csv is read and tested on inference pipeline too.\n",
        "### Expecting almost same proba values with predict_proba function at that pipeline too. It is a sanity check\n",
        "\n",
        "val_test = val_x.iloc[0:10]\n",
        "val_test_f = val_test.append(val_test).reset_index(drop = True)\n",
        "val_test_f.loc[10, 'feat_a'] = 'NA'\n",
        "val_test_f.loc[11, 'feat_b'] = 'NA'\n",
        "val_test_f.loc[12, 'feat_c'] = 'NA'\n",
        "val_test_f.loc[13, 'feat_d'] = 'NA'\n",
        "val_test_f.loc[14, 'feat_e'] = 'NA'\n",
        "val_test_f.loc[15, 'feat_f'] = 30\n",
        "val_test_f.loc[16, 'feat_g'] = 1000\n",
        "val_test_f.loc[17, 'feat_h'] = 0\n",
        "val_test_f.loc[18, 'feat_j'] = 70\n",
        "val_test_f.loc[19, 'feat_m'] = 'NA'\n",
        "\n",
        "print(val_test_f.head(20))\n",
        "\n",
        "val_test_f.to_csv(model_dir+\"val_test.csv\", index = False)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Il52vgB9tKXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_val3 = pd.DataFrame()\n",
        "for i in range(len(models)):\n",
        "  predictions_val3['proba' + str(i)] = models[i].predict_proba (val_test_f)[:,1] \n",
        "  predictions_val3['predict'+str(i)] = models[i].predict(val_test_f)\n",
        "\n",
        "predictions_val3['avg_proba'] = predictions_val3[[col for col in predictions_val3.columns if 'proba' in col]].mean(axis=1)\n",
        "predictions_val3['voted_is_sale'] = np.where(predictions_val3[[col for col in predictions_val3.columns if 'predict' in col]].sum(axis=1)/len(models) <0.5, 0,1) \n",
        "predictions_val3 = predictions_val3.join(val_y['is_sale'])\n",
        "\n",
        "conn_df_val = pd.DataFrame(val_conn_df, columns = ['conn_id']) \n",
        "predictions_val3['conn_id'] = conn_df_val.loc[:,'conn_id']\n",
        "\n",
        "fig, axs = plt.subplots(figsize = (8,12), nrows = 4)\n",
        "fig.suptitle('Vertically stacked subplots')\n",
        "\n",
        "for ii in range(len(groups_list)):\n",
        "\n",
        "  predictions_val3[\"PropensityGroup_bin\" +str(groups_list[ii])] = pd.cut(predictions_val3[\"avg_proba\"], bins=bins_dict[groups_list[ii]], labels=False, include_lowest=True) \n",
        "  predictions_val3.groupby([\"PropensityGroup_bin \"+str(groups_list[ii])])[\"avg_proba\"].agg([\"min\",\"max\", \"count\"]).reset_index()#.to_csv(f\" thresholds_{today_date}_all.csv\", index = False) \n",
        "  #print(predictions_val.groupby([\"PropensityGroup_bin\" + str(groups_list[ii])])[\"avg_proba\"].agg([\"min\",\"max\",\"count\"]))\n",
        "\n",
        "print(predictions_val3[\"PropensityGroup_bin40\"].value_counts())\n",
        "print(predictions_val3.head(20))"
      ],
      "metadata": {
        "id": "zmG2DnTdvhjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if (len(outsamp_df) > 0) and (len(outsamp_y) > 0):\n",
        "\n",
        "  predictions_outsamp = pd.DataFrame()\n",
        "  for i in range(len(models)):\n",
        "    predictions_outsamp['proba' + str(i)] = models[i].predict_proba(outsamp_df)[:,1]\n",
        "    predictions_outsamp['predict' + str(i)] = models[i].predict(outsamp_df)\n",
        "\n",
        "  predictions_outsamp['avg_proba'] = predictions_outsamp[[col for col in predictions_outsamp.columns if 'proba' in col]].mean(axis=1)\n",
        "  predictions_outsamp['voted_is_sale'] = np.where(predictions_outsamp[[col for col in predictions_outsamp.columns if 'predict' in col]].sum(axis=1)/len(models) <0.5, 0,1) \n",
        "  predictions_outsamp = predictions_outsamp.join(outsamp_y['is_sale'])\n",
        "\n",
        "  conn_df_outsamp = pd.DataFrame(outsamp_conn_df, columns = ['conn_id']) \n",
        "  predictions_outsamp['conn_id'] = conn_df_outsamp.loc[:,'conn_id']\n",
        "\n",
        "  #fig, axs = plt.subplots(figsize = (8,12), nrows = 4)\n",
        "  #fig.suptitle('Vertically stacked subplots')\n",
        "\n",
        "  for ii in range(len(groups_list)):\n",
        "    \n",
        "    predictions_outsamp[\"PropensityGroup_bin\" + str(groups_list[ii])] = pd.cut(predictions_outsamp[\"avg_proba\"], bins=bins_dict[groups_list[ii]], labels=False, include_lowest=True) \n",
        "    predictions_outsamp.groupby([\"PropensityGroup_bin\"+str(groups_list[ii])])[\"avg_proba\"].agg([\"min\", \"max\",\"count\"]).reset_index()#.to_csv(f\" thresholds_{today_date}_all.csv\", index = False) \n",
        "    \n",
        "    groups_outsamp = predictions_outsamp.groupby([\"PropensityGroup_bin\" +str(groups_list[ii])])[\"is_sale\"].agg([\"count\", \"mean\"]) \n",
        "    #groups_outsamp['mean'].plot(kind='bar', ax = axs[ii])\n",
        "    #plt.grid()"
      ],
      "metadata": {
        "id": "sgKT_ACZtKra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)\n",
        "publish_df = predictions.loc[:, ['conn_id', 'PropensityGroup_bin10', 'PropensityGroup_bin20', 'PropensityGroup_bin40', 'PropensityGroup_bin80']]\n",
        "publish_df_val = pd.concat([publish_df, predictions_val.loc[:, ['conn_id', 'PropensityGroup_binle', 'PropensityGroup_bin20', 'PropensityGroup_bin40', 'PropensityGroup_bin80']]], ignore_index=True)\n",
        "publish_df_all = pd.concat([publish_df_val, predictions_outsamp.loc[:, ['conn_id', 'PropensityGroup_bin10', 'PropensityGroup_bin20', 'PropensityGroup_bin40', 'PropensityGroup_bin80']]], ignore_index=True) \n",
        "print(publish_df_all)"
      ],
      "metadata": {
        "id": "dEE1Gq7Xsnsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, fl_score, confusion_matrix \n",
        "for i in range(len(models)):\n",
        "  #print(\"Model_\"+str(i)+\"_train AUC is (0:.3f}\".format(roc_auc_score(predictions['is_sale'], predictions['predict'+str(i)]))) \n",
        "  #print(\"Model_\"+str(i)+\"_train Accuracy is (0:.3f}\".format(accuracy_score(predictions['is_sale'], predictions['predict' + str(i)]))) \n",
        "  #print(\"Model \"+str(i)+\"_train Precision is (0:.3f}\".format(precision_score(predictions['is_sale'], predictions['predict'+str(i)]))) \n",
        "  #print(\"Model_\"+str(i)+\"_train Recall is (0:.3f}\".format(recall_score(predictions['is_sale'], predictions['predict' + str(i)]))) \n",
        "  #print(\"Model_\"+str(i)+\"_train F1 Score is (0:.3f}\".format(fl_score(predictions['is_sale'], predictions['predict'+str(i)]))) \n",
        "  \n",
        "  print(\"Model_\"+str(i)+\"_valid AUC is {0:.3f}\".format(roc_auc_score(predictions_val['is_sale'], predictions_val['predict' + str(i)]))) \n",
        "  print(\"Model \"+str(i)+\"_valid Accuracy is {0:.3f}\".format(accuracy_score(predictions_val['is_sale'], predictions_val['predict'+str(i)])))\n",
        "  print(\"Model \"+str(i)+\"_valid Precision is (0:.3f}\".format(precision_score(predictions_val['is_sale'], predictions_val['predict'+str(i)]))) \n",
        "  print(\"Model \"+str(i)+\"_valid Recall is (0:.3f}\".format(recall_score(predictions_val['is_sale'], predictions_val['predict'+str(i)]))) \n",
        "  print(\"Model_\"+str(i)+\"_valid F1 Score is {0:.3f}\".format(f1_score(predictions_val['is_sale'], predictions_val['predict'+str(i)]))) \n",
        "  \n",
        "#plot_cm(y_true,y_pred, 'Confusion Matrix for LGB Model')"
      ],
      "metadata": {
        "id": "KS3OOh_-snwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cm(y_true, y_pred, title):\n",
        "  figsize = (5, 5)\n",
        "  y_pred = y_pred.astype (int)\n",
        "  cm = confusion_matrix(y_true, y_pred, labels=np.unique(y_true))\n",
        "  cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
        "  cm_perc = cm / cm_sum.astype(float) * 100\n",
        "  annot= np.empty_like(cm).astype(str)\n",
        "  nrows, ncols = cm.shape\n",
        "  for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "      c = cm[i, j]\n",
        "      p = cm_perc[i, j]\n",
        "      if i == j:\n",
        "        s = cm_sum[i]\n",
        "        annot[i, j] = '%.1f%%\\n\\%d/%d' % (p, c, s)\n",
        "      elif c == 0:\n",
        "        annot[i, j] = ''\n",
        "      else:\n",
        "        annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
        "  cm = pd.DataFrame(cm, index=np.unique(y_true), columns=np.unique(y_true)) \n",
        "  cm.index.name = 'Actual'\n",
        "  cm.columns.name = 'Predicted'\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  plt.title(title)\n",
        "  sns.heatmap(cm, cmap=\"YLGnBu\", annot=annot, fmt='', ax=ax)"
      ],
      "metadata": {
        "id": "c107cEnksn0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_cm(predictions['is_sale'], predictions['voted_is_sale'], 'Train_Confusion_Matrix') \n",
        "plot_cm(predictions_val['is_sale'], predictions_val['voted_is_sale'], 'Validation_Confusion_Matrix')"
      ],
      "metadata": {
        "id": "1xQtnZkBsn3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "publish_df_all['calltime'] = '2023-01-01 01:00:00'\n",
        "publish_df_all['calltime'] = publish_df_all['calltime'].astype('datetime64')\n",
        "print(publish_df_all.head())"
      ],
      "metadata": {
        "id": "0nHIHe35viJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sqlalchemy as sa\n",
        "from sqlalchemy import create_engine\n",
        "from sqlalchemy.engine import url as sa_url\n",
        "\n",
        "def create_mysql_engine(host, database, username, password, port='3307'):\n",
        "\n",
        "  url = sa_url.URL(drivername= 'mysql+pymysql', host=host, port=port, database=database, username=username, password=password)\n",
        "  print(url)\n",
        "  return sa.create_engine(url)\n",
        "\n",
        "engine=create_mysql_engine(ai['host'], 'smexplorerdata_fbb', ai['user'], ai['password'], ai['port'])\n",
        "\n",
        "publish_df_all.to_sql(if_exists = 'replace', name= 'fbb_retention_propensity_groups_nobtn_nopivot', con = engine, schema= 'smexplorerdata_fbb', index = False)"
      ],
      "metadata": {
        "id": "XHzQcncbviNS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engine=create_mysql_engine(ai['host'], 'smexplorerdata_fbb', ai['user'], ai['password'], ai['port'])\n",
        "\n",
        "with engine.connect() as con:\n",
        "  con.execute('CREATE INDEX fbb_retention_propensity_groups_nobtn_nopivot_conn_id_IDX USING BTREE ON smexplorerdata_fbb.fbb_retention_propensity_groups_nobtn_nopivot (conn_id (16));')"
      ],
      "metadata": {
        "id": "sfcOSaUAwFrs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}